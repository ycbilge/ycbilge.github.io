<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yunus Can Bilge</title>

    <meta name="author" content="Yunus Can Bilge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yunus Can Bilge
                </p>
                <p>
		I'm an Assistant Professor of Computer Science at Institute of Informatics at Hacettepe University. I have received a PhD degree in Computer Engineering from Hacettepe University. My PhD focused on learning sign languages with limited supervision and semantic representations.
		
                </p>
                <p style="text-align:center">
                  <a href="mailto:yunuscan.bilge@hacettepe.edu.tr">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/TODO.pdf">CV</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=woDfihgAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/bilge_yc">X</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ycbilge/">Github</a> &nbsp;/&nbsp;
		  <a href="#news">News</a> &nbsp;/&nbsp;
	          <a href="#research">Research</a> &nbsp;/&nbsp;
		  <a href="#publications">Selected Publications</a> &nbsp;/&nbsp;
                  <a href="#teaching">Teaching</a> &nbsp;/&nbsp;
		  <a href="#patents">Patents</a> &nbsp;/&nbsp;
                  <a href="#blog">Blog</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/ybilge.jpg"><img style="width:70%;max-width:70%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ybilge.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

	  <table id="news" style="width:100%;margin:auto;"><tbody>
          <tr><td style="padding:16px;">
          <h2>News</h2>
          <ul>
           <li><b>[July 2025]</b> <strong>I am looking for highly motivated graduate students and research interns interested in either multimodal machine learning or machine learning systems in production.</strong> Please send an <a href="mailto:yunuscan.bilge@hacettepe.edu.tr">email</a> if interested.
           </li>
          <li><b>[June 2025]</b> New paper at  <a href="https://www.sciencedirect.com/journal/knowledge-based-systems" target="_blank">Knowledge Based Systems</a>: <a href = "https://www.sciencedirect.com/science/article/pii/S0950705125006033" target="_blank">Modest: A dataset for multi domain scientific title generation</a></li>
          <li><b>[June 2025]</b> joined Hacettepe University as an assistant professor of computer science.</li>

          </ul>
        </td></tr>
      </tbody></table>
          <table id="research" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in 
			<ul>
		          <li>machine learning  (data-efficient machine learning with minimal supervision ; zero-shot, few-shot, self-supervised learning), </li>
		          <li>computer vision (image and video understanding), </li>
		          <li>multimodal machine learning (integrate and reason over multiple data modalities—such as text, vision, and audio), </li>
		          <li>machine learning in production  (focusing on the deployment and scalability of machine learning systems in real-world settings).</li>
			</ul>
			 Previously, I worked on sign language processing and machine learning systems in video surveillance settings. 
                </p>
              </td>
            </tr>
          </tbody></table>
          
  <table id="publications" style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    <h2>Selected Publications</h2>
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/modest.png" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/modest.png' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/pii/S0950705125006033">
          <span class="papertitle">MoDeST: A dataset for Multi Domain Scientific Title Generation</span>
        </a>
        <br>
        N. Bolucu,
        
		<strong>Y. C. Bilge</strong>,
        D. Cetintas,
        Z. Yucel
        <br>
        <em>Knowledge-Based Systems</em>, May 2025.
        <br>
        <!-- <a href="https://">project page</a> -->
        
        <p></p>
        <p>
		The paper introduces MoDeST, a multi-domain and multilingual dataset for scientific title generation in English and Turkish, evaluates large language models across various scientific input types and learning settings, and highlights the effectiveness of abstracts and domain-specific modeling for improving title generation performance.
        </p>
      </td>
    </tr>
    <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
          <source src="images/cross.jpg" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cross.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('bog_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('bog_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
     <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320324001250/">
    <span class="papertitle">Cross-lingual few-shot sign language recognition</span>
        </a>
        <br>
        <strong>Y. C. Bilge</strong>,
        <a href="https://web.cs.hacettepe.edu.tr/~nazli//">N. İ. Cinbis</a>,
        <a href="https://user.ceng.metu.edu.tr/~gcinbis/">R. G. Cinbis</a>   
        <br>
        <em>Pattern Recognition</em>, Feb. 2024.
        <br>
        <p></p>
        <p>
        We address zero-shot sign language recognition by leveraging textual and attribute-based semantic class representations from sign language dictionaries, introducing three benchmark datasets and a spatiotemporal recognition model that integrates visual and semantic features to recognize previously unseen sign classes.
        </p>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
      <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
      <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
      <source src="images/tpami22zslsign.jpg" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='images/tpami22zslsign.jpg' width=100%>
      </div>
      <script type="text/javascript">
        function bog_start() {
          document.getElementById('bog_image').style.opacity = "1";
        }

        function bog_stop() {
          document.getElementById('bog_image').style.opacity = "0";
        }
        bog_stop()
      </script>
    </td>
     <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/abstract/document/9681230/">
    <span class="papertitle">Towards Zero-Shot Sign Language Recognition</span>
        </a>
        <br>
        <strong>Y. C. Bilge</strong>,
        <a href="https://user.ceng.metu.edu.tr/~gcinbis/">R. G. Cinbis</a>   
        <a href="https://web.cs.hacettepe.edu.tr/~nazli//">N. İ. Cinbis</a>,
        <br>
        <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, Jan. 2022.
        <br>
        <p></p>
        <p>
        We propose a novel embedding-based framework for few-shot sign language recognition (FSSLR) in cross-lingual settings, leveraging spatio-temporal visual and hand landmark features, and introducing three multilingual benchmarks to demonstrate its effectiveness in recognizing novel signs in unseen languages with limited examples.
        </p>
      </td>
      <!--- -->
     <td style="padding:8px;width:80%;vertical-align:middle">
      <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
      <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
      <source src="images/wacv21.jpg" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='images/wacv21.jpg' width=100%>
      </div>
      <script type="text/javascript">
        function bog_start() {
          document.getElementById('bog_image').style.opacity = "1";
        }

        function bog_stop() {
          document.getElementById('bog_image').style.opacity = "0";
        }
        bog_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/WACV2021/html/Bilge_Red_Carpet_to_Fight_Club_Partially-Supervised_Domain_Transfer_for_Face_WACV_2021_paper.html">
    <span class="papertitle">Red Carpet to Fight Club: Partially-supervised Domain Transfer for Face Recognition in Violent Videos</span>
        </a>
        <br>
        <strong>Y. C. Bilge</strong>,
        M. K. Yucel,
        <a href="https://web.cs.hacettepe.edu.tr/~nazli/">N. İ. Cinbis</a>,
        <a href="https://avesis.hacettepe.edu.tr/pinar.duygulu/">P. Duygulu</a>,
        <a href="https://user.ceng.metu.edu.tr/~gcinbis/">R. G. Cinbis</a>   
        
        <br>
        <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, Jan. 2021.
        <br>
        <p></p>
        <p>
        We introduce the "WildestFaces" dataset and a novel clean-to-violent domain transfer framework for recognizing individuals in violent videos using models trained on clean ID photos, addressing challenges of domain discrepancy, limited video data, through stacked affine-transforms, attention-driven temporal adaptation, and a self-attention-based model.
        </p>
      </td>
      <!--- -->
            <!--- -->
     <td style="padding:8px;width:80%;vertical-align:middle">
      <tr onmouseout="bog_stop()" onmouseover="bog_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
      <div class="two" id='bog_image'><video  width=100% muted autoplay loop>
      <source src="images/bmvc19sign.jpg" type="video/mp4">
      Your browser does not support the video tag.
      </video></div>
      <img src='images/bmvc19sign.jpg' width=100%>
      </div>
      <script type="text/javascript">
        function bog_start() {
          document.getElementById('bog_image').style.opacity = "1";
        }

        function bog_stop() {
          document.getElementById('bog_image').style.opacity = "0";
        }
        bog_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://openaccess.thecvf.com/content/WACV2021/html/Bilge_Red_Carpet_to_Fight_Club_Partially-Supervised_Domain_Transfer_for_Face_WACV_2021_paper.html">
    <span class="papertitle">Zero-Shot Sign Language Recognition: Can Textual Data Uncover Sign Languages?</span>
        </a>
        <br>
        <strong>Y. C. Bilge</strong>,
        <a href="https://web.cs.hacettepe.edu.tr/~nazli/">N. İ. Cinbis</a>,
        <a href="https://user.ceng.metu.edu.tr/~gcinbis/">R. G. Cinbis</a>   
        
        <br>
        <em>British Machine Vision Conference (BMVC)</em>,  September 2019.
        <br>
        <p></p>
        <p>
        The paper introduces the zero-shot sign language recognition (ZSSLR) problem using the ASL-Text dataset with 250 classes and textual descriptions, proposing a spatiotemporal framework combining 3D-CNNs, BiLSTMs, and text embeddings to recognize unseen signs by leveraging dictionary-based semantic representations.
        </p>
      </td>

      <!--- -->
    </tbody>
  </table>

<table id="teaching" style="width:100%;margin:auto;"><tbody>

  <h2>Teaching</h2>
  <ul>
    <li><b>COM4513 Special Topics I (Computer Vision) </b>, Department of Computer Engineering, Ankara University, Fall 2024 - 2025.</li>
    <li><b>COM3548 - Pattern Recognition </b>, Department of Computer Engineering, Ankara University, Spring 2023 - 2024.</li>
    <li><b>COM4523 - Artificial Neural Networks</b>, Department of Computer Engineering, Ankara University, Fall 2023 - 2024.</li>
  </ul>

</tbody></table>



	  
  <table id="patents" style="width:100%;margin:auto;"><tbody>
  <h2> Patents </h2>
    <span class="papertitle">A Method for Real-Time Running Detection and Tracking in Video Footage, National.</span>

        </a>
        <br>
        <strong>Y. C. Bilge et. al. </strong>
        <br>
        <em>2023 013301</em>,  21.02.2025.
        <br>
    <span class="papertitle">Calibration of Angle Measuring Sensors (IMU) In Portable Devices Using DEM and Landform Signature, National.</span>

        </a>
        <br>
        <strong>Y. C. Bilge et. al. </strong>
        <br>
        <em>2023 003176</em>,  21.02.2024.
        <br>
  </tbody></table>
<table id="blog" style="width:100%;margin:auto;"><tbody>
  <h2> Blog </h2>
    <span class="papertitle">Everyone Talks About AI, But Who Understands It?</span>
        </a>
        <br>
        <strong>in <a href="blog/ai_literacy.html"><b>English</b></a> </strong>, <strong>  <a href="blog/yz_tr.html"><b>Yapay Zekâyı Herkes Konuşuyor, Peki Kim Anlıyor?</b></a>  </strong>
        <br>
        <em>June</em>, 2025.
        <br>
   
  </tbody></table>

  </tbody>
  </table>

            




<!-- -->          





    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Based on the template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
          </p>
        </td>
      </tr>
    </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
